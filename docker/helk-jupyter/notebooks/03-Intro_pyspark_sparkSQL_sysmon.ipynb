{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to Elasticsearch and Spark SQL via Pyspark**\n",
    "----------------------------------------------------------------------------\n",
    "## Goals:\n",
    "* Practice Spark SQL via PySpark skills\n",
    "* Ensure JupyterLab Server, Spark Cluster & Elasticsearch are communicating\n",
    "* Learn to read from HELK elasticsearch indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SparkSession Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SparkSession instance\n",
    "* Define a **spark** variable\n",
    "* Pass values to the **appName** and **master** functions\n",
    "    * For the master function, we are going to use the HELK's Spark Master container (helk-spark-master)\n",
    "* This time add the **config()** function to set Elasticsearch information needed to read from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**config(key=None, value=None, conf=None)**](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SparkSession.Builder.config)\n",
    "* Sets a config option.\n",
    "* Options set using this method are automatically propagated to both SparkConf and SparkSessionâ€™s own configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HELK Reader\") \\\n",
    "    .master(\"spark://helk-spark-master:7077\") \\\n",
    "    .config(\"es.read.field.as.array.include\", \"tags\") \\\n",
    "    .config(\"es.nodes\",\"helk-elasticsearch:9200\") \\\n",
    "    .config(\"es.net.http.auth.user\",\"elastic\") \\\n",
    "    .config(\"es.net.http.auth.pass\",\"elasticpassword\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "    #PLEASE REMEMBER!!!!\n",
    "    #If you are using elastic TRIAL license, then you need the es.net.http.auth.pass value\n",
    "    #If you are using elastic BASIC license, then you can remove the es.net.http.auth.pass value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the SparkSession variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://403892d82956:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://helk-spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HELK Reader</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fec09293978>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from the HELK Elasticsearch via Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Dataframe API to access Elasticsearch index (Elasticsearch-Sysmon Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we know, Spark SQL is a Spark module for structured data processing, and provides a programming abstraction called DataFrames and can also act as distributed SQL query engine.\n",
    "* Elasticsearch becomes a native source for Spark SQL so that data can be indexed and queried from Spark SQL transparently\n",
    "* Spark SQL works with structured data - in other words, all entries are expected to have the same structure (same number of fields, of the same type and name)\n",
    "* Using unstructured data (documents with different structures) is not supported and will cause problems.\n",
    "* Through the **org.elasticsearch.spark.sql** package, esDF methods are available on the SQLContext API\n",
    "\n",
    "Reference: https://www.elastic.co/guide/en/elasticsearch/hadoop/current/spark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_reader = (spark\n",
    "          .read\n",
    "          .format(\"org.elasticsearch.spark.sql\")\n",
    "          .option(\"inferSchema\", \"true\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**load(path=None, format=None, schema=None, **options)**](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.load)\n",
    "* Loads data from a data source and returns it as a :class`DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sysmon_df = es_reader.load(\"logs-endpoint-winevent-sysmon-*/doc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter our the data to only show certain data fields and events with the action **\"processcreate\"** which is Sysmon Event ID 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processcreate_df = sysmon_df.filter(sysmon_df.action == \"processcreate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select a few columns from your dataframe with the **select** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processcreate_df = processcreate_df.select(\"process_guid\",\"process_parent_name\",\"process_parent_command_line\",\"process_name\",\"process_command_line\",\"action\",\"@timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------------------+-------------+--------------------+-------------+--------------------+\n",
      "|        process_guid|process_parent_name|process_parent_command_line| process_name|process_command_line|       action|          @timestamp|\n",
      "+--------------------+-------------------+---------------------------+-------------+--------------------+-------------+--------------------+\n",
      "|1C9FDC81-9806-5C6...|            cmd.exe|       c:\\windows\\system...|  conhost.exe|\\??\\c:\\windows\\sy...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-9806-5C6...|        svchost.exe|       c:\\windows\\system...|taskhostw.exe|taskhostw.exe ngc...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-9807-5C6...|        svchost.exe|       c:\\windows\\system...| wsqmcons.exe|c:\\windows\\system...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-9809-5C6...|       gpupdate.exe|       gpupdate.exe /tar...|  conhost.exe|\\??\\c:\\windows\\sy...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-980A-5C6...|       services.exe|       c:\\windows\\system...|  svchost.exe|c:\\windows\\system...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-980A-5C6...|        svchost.exe|       c:\\windows\\system...|   wermgr.exe|c:\\windows\\system...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-980B-5C6...|       services.exe|       c:\\windows\\system...|  svchost.exe|c:\\windows\\system...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-980C-5C6...|        svchost.exe|       c:\\windows\\system...|taskhostw.exe|taskhostw.exe net...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-980D-5C6...|        svchost.exe|       c:\\windows\\system...|    hxtsr.exe|\"c:\\program files...|processcreate|2019-02-22 06:34:...|\n",
      "|1C9FDC81-9806-5C6...|       vmtoolsd.exe|       \"c:\\program files...|      cmd.exe|c:\\windows\\system...|processcreate|2019-02-22 06:34:...|\n",
      "+--------------------+-------------------+---------------------------+-------------+--------------------+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processcreate_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes from the original Sysmon Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filter the original **sysmon_df** dataframe\n",
    "* Select specific columns\n",
    "* display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetworkConnect Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the network events logged by Sysmon (Event ID 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkconnect_df = sysmon_df.filter(sysmon_df.action == \"networkconnect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkconnect_df = networkconnect_df.select(\"process_guid\",\"dst_ip_addr\",\"dst_port\",\"dst_host_name\",\"action\",\"@timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---------------+--------+-------------------------------+--------------+-----------------------+\n",
      "|process_guid                        |dst_ip_addr    |dst_port|dst_host_name                  |action        |@timestamp             |\n",
      "+------------------------------------+---------------+--------+-------------------------------+--------------+-----------------------+\n",
      "|1C9FDC81-84E5-5C6D-0000-001060530400|239.255.255.250|1900    |null                           |networkconnect|2019-02-22 06:34:47.078|\n",
      "|1C9FDC81-84E5-5C6D-0000-001060530400|127.0.0.1      |56783   |desktop-lfd11qp.rivendell.local|networkconnect|2019-02-22 06:34:47.078|\n",
      "|1C9FDC81-84E5-5C6D-0000-001060530400|null           |56781   |desktop-lfd11qp.rivendell.local|networkconnect|2019-02-22 06:34:47.484|\n",
      "|1C9FDC81-84CA-5C6D-0000-0010262D0100|null           |53      |null                           |networkconnect|2019-02-22 06:34:49.839|\n",
      "|1C9FDC81-84CA-5C6D-0000-0010262D0100|null           |53      |null                           |networkconnect|2019-02-22 06:34:49.839|\n",
      "|1C9FDC81-84CA-5C6D-0000-0010262D0100|null           |5355    |null                           |networkconnect|2019-02-22 06:34:50.714|\n",
      "|1C9FDC81-84CA-5C6D-0000-0010262D0100|192.168.64.2   |53      |null                           |networkconnect|2019-02-22 06:34:50.714|\n",
      "|1C9FDC81-84C4-5C6D-0000-0010EB030000|192.168.64.255 |137     |null                           |networkconnect|2019-02-22 06:34:53.942|\n",
      "|1C9FDC81-84C4-5C6D-0000-0010EB030000|192.168.64.137 |137     |desktop-lfd11qp.rivendell.local|networkconnect|2019-02-22 06:34:53.942|\n",
      "|1C9FDC81-84E5-5C6D-0000-001060530400|null           |61557   |desktop-lfd11qp.rivendell.local|networkconnect|2019-02-22 06:34:47.484|\n",
      "+------------------------------------+---------------+--------+-------------------------------+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "networkconnect_df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FileCreate Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecreate_df = sysmon_df.filter(sysmon_df.action == \"filecreate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecreate_df = filecreate_df.select(\"process_guid\",\"file_name\",\"action\",\"@timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+-----------------------+\n",
      "|process_guid                        |file_name                                                                                                                                                                            |action    |@timestamp             |\n",
      "+------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+-----------------------+\n",
      "|1C9FDC81-980B-5C6F-0000-00109B5CD100|c:\\programdata\\regid.1991-06.com.microsoft\\regid.1991-06.com.microsoft_windows-10-pro.swidtag                                                                                        |filecreate|2019-02-22 06:34:52.38 |\n",
      "|1C9FDC81-850A-5C6D-0000-0010978A0500|c:\\users\\cbrown\\appdata\\local\\microsoft\\penworkspace\\discovercachedata.dat                                                                                                           |filecreate|2019-02-22 06:34:53.328|\n",
      "|1C9FDC81-84CA-5C6D-0000-00109F2C0100|c:\\windows\\prefetch\\ipconfig.exe-eea91845.pf                                                                                                                                         |filecreate|2019-02-22 06:34:53.841|\n",
      "|1C9FDC81-850E-5C6D-0000-001049410600|c:\\users\\cbrown\\appdata\\local\\packages\\microsoft.windows.cortana_cw5n1h2txyewy\\localstate\\devicesearchcache\\appcache131952908968534553.txt                                           |filecreate|2019-02-22 06:34:59.983|\n",
      "|1C9FDC81-850E-5C6D-0000-001049410600|c:\\users\\cbrown\\appdata\\local\\packages\\microsoft.windows.cortana_cw5n1h2txyewy\\localstate\\constraintindex\\apps_{34237869-b2e1-400f-8de7-90f3e51dd298}                                |filecreate|2019-02-22 06:35:00.621|\n",
      "|1C9FDC81-850E-5C6D-0000-001049410600|c:\\users\\cbrown\\appdata\\local\\packages\\microsoft.windows.cortana_cw5n1h2txyewy\\localstate\\constraintindex\\apps_{34237869-b2e1-400f-8de7-90f3e51dd298}\\0.0.filtertrie.intermediate.txt|filecreate|2019-02-22 06:35:00.752|\n",
      "|1C9FDC81-850E-5C6D-0000-001049410600|c:\\users\\cbrown\\appdata\\local\\packages\\microsoft.windows.cortana_cw5n1h2txyewy\\localstate\\constraintindex\\apps_{34237869-b2e1-400f-8de7-90f3e51dd298}\\0.2.filtertrie.intermediate.txt|filecreate|2019-02-22 06:35:00.756|\n",
      "|1C9FDC81-850E-5C6D-0000-001049410600|c:\\users\\cbrown\\appdata\\local\\packages\\microsoft.windows.cortana_cw5n1h2txyewy\\localstate\\constraintindex\\apps_{34237869-b2e1-400f-8de7-90f3e51dd298}\\0.1.filtertrie.intermediate.txt|filecreate|2019-02-22 06:35:00.755|\n",
      "|1C9FDC81-850E-5C6D-0000-001049410600|c:\\users\\cbrown\\appdata\\local\\packages\\microsoft.windows.cortana_cw5n1h2txyewy\\localstate\\constraintindex\\apps_{34237869-b2e1-400f-8de7-90f3e51dd298}\\apps.ft                        |filecreate|2019-02-22 06:35:00.771|\n",
      "|1C9FDC81-84CA-5C6D-0000-00109F2C0100|c:\\windows\\prefetch\\conhost.exe-f98a1078.pf                                                                                                                                          |filecreate|2019-02-22 06:35:03.776|\n",
      "+------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filecreate_df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark SQL JOINs & Sysmon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**join(other, on=None, how=None)**](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.join)\n",
    "\n",
    "Joins with another DataFrame, using the given join expression.\n",
    "\n",
    "Parameters:\t\n",
    "* **other** â€“ Right side of the join\n",
    "* **on** â€“ a string for the join column name, a list of column names, a join expression (Column), or a list of Columns. If on is a string or a list of strings indicating the name of the join column(s), the column(s) must exist on both sides, and this performs an equi-join.\n",
    "* **how** â€“ str, default inner. Must be one of: inner, cross, outer, full, full_outer, left, left_outer, right, right_outer, left_semi, and left_anti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcessCreate -> NetworkCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_network_df = processcreate_df.join(networkconnect_df, \"process_guid\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+--------------+\n",
      "|process_parent_name|process_name          |dst_ip_addr   |\n",
      "+-------------------+----------------------+--------------+\n",
      "|svchost.exe        |backgroundtaskhost.exe|204.79.197.200|\n",
      "|svchost.exe        |backgroundtaskhost.exe|40.112.91.29  |\n",
      "|svchost.exe        |backgroundtaskhost.exe|40.112.91.29  |\n",
      "|svchost.exe        |backgroundtaskhost.exe|40.112.91.29  |\n",
      "|svchost.exe        |backgroundtaskhost.exe|40.112.91.29  |\n",
      "+-------------------+----------------------+--------------+\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 6.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_network_df.select(\"process_parent_name\",\"process_name\",\"dst_ip_addr\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|process_parent_name|count|\n",
      "+-------------------+-----+\n",
      "|        svchost.exe|    5|\n",
      "+-------------------+-----+\n",
      "\n",
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 7.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_network_df.groupBy('process_parent_name').count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+----------------------+--------------+\n",
      "|process_parent_command_line                     |process_name          |dst_ip_addr   |\n",
      "+------------------------------------------------+----------------------+--------------+\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|backgroundtaskhost.exe|204.79.197.200|\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|backgroundtaskhost.exe|40.112.91.29  |\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|backgroundtaskhost.exe|40.112.91.29  |\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|backgroundtaskhost.exe|40.112.91.29  |\n",
      "|c:\\windows\\system32\\svchost.exe -k dcomlaunch -p|backgroundtaskhost.exe|40.112.91.29  |\n",
      "+------------------------------------------------+----------------------+--------------+\n",
      "\n",
      "CPU times: user 0 ns, sys: 12 ms, total: 12 ms\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(process_network_df\n",
    "            .filter(process_network_df\n",
    "            .process_parent_name==\"svchost.exe\")\n",
    "            .select(\"process_parent_command_line\",\"process_name\",\"dst_ip_addr\")\n",
    "            .show(5,truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcessCreate -> FileCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus now on the least frequent events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file_df = processcreate_df.join(filecreate_df, \"process_guid\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|process_parent_name|count|\n",
      "+-------------------+-----+\n",
      "|       services.exe|    2|\n",
      "|        svchost.exe|   19|\n",
      "+-------------------+-----+\n",
      "\n",
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_file_df.groupBy('process_parent_name').count().sort('count').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark_Python3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
